import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  TextInput,
  TouchableOpacity,
  FlatList,
  StyleSheet,
  KeyboardAvoidingView,
  Platform,
  Alert,
  ActivityIndicator,
  Dimensions,
} from 'react-native';
import { Asset } from 'expo-asset';
import * as FileSystem from 'expo-file-system';

// Type definitions for message structure
interface Message {
  id: string;
  text: string;
  sender: 'user' | 'assistant' | 'system';
  timestamp: string;
}

// Mock LlamaContext interface for now (replace when actual package is available)
interface LlamaContextType {
  completion: (prompt: string, options: any) => Promise<string>;
}

// Get screen dimensions for responsive design
const { width: screenWidth, height: screenHeight } = Dimensions.get('window');

/**
 * LocalChatbot Component
 * 
 * An offline-first disaster relief chatbot designed for emergency situations
 * in areas like Cebu City, Philippines. This component provides:
 * 
 * - Complete offline functionality using a local GGUF model
 * - Conversational AI assistance for disaster relief scenarios
 * - Optimized UI for mobile devices
 * - No internet connection required during runtime
 * 
 * The chatbot is pre-loaded with disaster relief knowledge and can provide
 * guidance on emergency procedures, safety protocols, and resource locations.
 */
const LocalChatbot = () => {
  const [messages, setMessages] = useState<Message[]>([
    {
      id: '1',
      text: 'Hello! I am your offline disaster relief assistant. I can help you with emergency procedures, safety information, and resource guidance. How can I assist you today?',
      sender: 'assistant',
      timestamp: new Date().toISOString(),
    },
  ]);
  const [inputText, setInputText] = useState('');
  const [llamaContext, setLlamaContext] = useState<LlamaContextType | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [isTyping, setIsTyping] = useState(false);
  const [modelStatus, setModelStatus] = useState<'initializing' | 'loading' | 'ready' | 'error'>('initializing');
  
  // Ref for FlatList to enable auto-scrolling
  const flatListRef = useRef<FlatList>(null);

  /**
   * Initialize the LLaMA model on component mount
   * This loads the offline model from the assets/models directory
   */
  useEffect(() => {
    initializeModel();
  }, []);

  /**
   * Initialize the local LLaMA model for offline inference
   * Handles model loading, error cases, and user feedback
   * NOTE: This is a simplified implementation for demonstration.
   * In production, replace with actual react-native-llm-mediapipe integration.
   */
  const initializeModel = async () => {
    try {
      setModelStatus('loading');
      setIsLoading(true);

      // Simulate model loading for demonstration
      // In production, replace this with actual LlamaContext.initFromAsset
      console.log('ðŸ¤– Initializing offline chatbot model...');
      
      // Simulate loading time
      await new Promise(resolve => setTimeout(resolve, 3000));
      
      // For demo purposes, we'll create a mock context
      const mockContext: LlamaContextType = {
        completion: async (prompt: string, options: any) => {
          // Simple mock responses for demonstration
          const responses = [
            "For emergency situations, first ensure your safety. Move to higher ground if there's flooding.",
            "Always keep emergency supplies including water, food, flashlight, and first aid kit ready.",
            "In case of typhoon, secure windows, stay indoors, and listen to official announcements.",
            "Emergency contact numbers: 911 for general emergencies, Red Cross for disaster relief.",
            "Create an evacuation plan with your family and practice it regularly."
          ];
          return responses[Math.floor(Math.random() * responses.length)];
        }
      };

      setLlamaContext(mockContext);
      setModelStatus('ready');
      setIsLoading(false);
      
      console.log('âœ… Offline chatbot model loaded successfully!');
      
      // Add a system message to confirm the model is ready
      const systemMessage: Message = {
        id: Date.now().toString(),
        text: 'ðŸŸ¢ Offline model loaded successfully! I\'m ready to assist you with disaster relief guidance.',
        sender: 'system',
        timestamp: new Date().toISOString(),
      };
      
      setMessages(prev => [...prev, systemMessage]);

    } catch (error) {
      console.error('âŒ Error initializing chatbot model:', error);
      setModelStatus('error');
      setIsLoading(false);
      
      const errorMessage: Message = {
        id: Date.now().toString(),
        text: `âŒ Failed to load offline model: ${(error as Error).message}. Please ensure you have run the setup script and the model file is present.`,
        sender: 'system',
        timestamp: new Date().toISOString(),
      };
      
      setMessages(prev => [...prev, errorMessage]);
      
      Alert.alert(
        'Model Loading Error',
        'Failed to load the offline chatbot model. Please check that you have run setup_model.sh and the model file is present.',
        [{ text: 'OK' }]
      );
    }
  };

  /**
   * Handle sending a new message
   * Processes user input and generates AI response using the local model
   */
  const handleSend = async () => {
    if (!inputText.trim() || !llamaContext || isTyping) {
      return;
    }

    const userMessage: Message = {
      id: Date.now().toString(),
      text: inputText.trim(),
      sender: 'user',
      timestamp: new Date().toISOString(),
    };

    // Add user message to chat
    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setIsTyping(true);

    try {
      // Construct conversation context for the AI
      const conversationHistory = messages
        .filter(msg => msg.sender !== 'system')
        .slice(-10) // Keep last 10 messages for context
        .map(msg => `${msg.sender === 'user' ? 'Human' : 'Assistant'}: ${msg.text}`)
        .join('\n');

      // Create a disaster relief focused prompt
      const prompt = `You are an offline disaster relief assistant for emergency situations in Cebu City, Philippines. You provide helpful, accurate, and concise guidance on:

- Emergency procedures and safety protocols
- Disaster preparedness and response
- First aid and medical assistance
- Evacuation procedures and safe locations
- Resource locations (shelters, hospitals, emergency services)
- Communication during emergencies
- Water and food safety during disasters

Previous conversation:
${conversationHistory}

Current Human: ${userMessage.text}
Assistant: `;

      console.log('ðŸ¤– Generating response...');
      
      // Generate response using the local model
      const response = await llamaContext.completion(prompt, {
        temperature: 0.7,
        maxTokens: 150,        // Limit response length for mobile
        stopStrings: ['Human:', 'Assistant:', '\n\n'],
      });

      console.log('âœ… Response generated:', response);

      // Create assistant message
      const assistantMessage: Message = {
        id: Date.now().toString(),
        text: response.trim() || 'I apologize, but I couldn\'t generate a response. Please try rephrasing your question.',
        sender: 'assistant',
        timestamp: new Date().toISOString(),
      };

      setMessages(prev => [...prev, assistantMessage]);

    } catch (error) {
      console.error('âŒ Error generating response:', error);
      
      // Handle error gracefully
      const errorMessage: Message = {
        id: Date.now().toString(),
        text: 'I apologize, but I encountered an error while processing your request. Please try again.',
        sender: 'assistant',
        timestamp: new Date().toISOString(),
      };
      
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsTyping(false);
    }
  };

  /**
   * Render individual chat message
   * Applies different styling for user, assistant, and system messages
   */
  const renderMessage = ({ item }: { item: Message }) => {
    const isUser = item.sender === 'user';
    const isSystem = item.sender === 'system';
    
    return (
      <View style={[
        styles.messageContainer,
        isUser ? styles.userMessageContainer : styles.assistantMessageContainer,
        isSystem && styles.systemMessageContainer
      ]}>
        <View style={[
          styles.messageBubble,
          isUser ? styles.userBubble : styles.assistantBubble,
          isSystem && styles.systemBubble
        ]}>
          <Text style={[
            styles.messageText,
            isUser ? styles.userText : styles.assistantText,
            isSystem && styles.systemText
          ]}>
            {item.text}
          </Text>
          <Text style={[
            styles.timestamp,
            isUser ? styles.userTimestamp : styles.assistantTimestamp
          ]}>
            {new Date(item.timestamp).toLocaleTimeString([], { 
              hour: '2-digit', 
              minute: '2-digit' 
            })}
          </Text>
        </View>
      </View>
    );
  };

  /**
   * Scroll to bottom when new messages are added
   */
  useEffect(() => {
    if (flatListRef.current && messages.length > 0) {
      setTimeout(() => {
        flatListRef.current?.scrollToEnd({ animated: true });
      }, 100);
    }
  }, [messages]);

  return (
    <KeyboardAvoidingView 
      style={styles.container}
      behavior={Platform.OS === 'ios' ? 'padding' : 'height'}
      keyboardVerticalOffset={Platform.OS === 'ios' ? 90 : 0}
    >
      {/* Header */}
      <View style={styles.header}>
        <Text style={styles.headerTitle}>ðŸš¨ Disaster Relief Assistant</Text>
        <View style={[styles.statusIndicator, {
          backgroundColor: modelStatus === 'ready' ? '#4CAF50' : 
                          modelStatus === 'loading' ? '#FF9800' : '#F44336'
        }]}>
          <Text style={styles.statusText}>
            {modelStatus === 'ready' ? 'ðŸŸ¢ Offline Ready' : 
             modelStatus === 'loading' ? 'ðŸŸ¡ Loading...' : 'ðŸ”´ Error'}
          </Text>
        </View>
      </View>

      {/* Messages List */}
      <FlatList
        ref={flatListRef}
        data={messages}
        renderItem={renderMessage}
        keyExtractor={(item) => item.id}
        style={styles.messagesList}
        contentContainerStyle={styles.messagesContent}
        showsVerticalScrollIndicator={false}
      />

      {/* Typing Indicator */}
      {isTyping && (
        <View style={styles.typingContainer}>
          <ActivityIndicator size="small" color="#007AFF" />
          <Text style={styles.typingText}>Assistant is typing...</Text>
        </View>
      )}

      {/* Input Area */}
      <View style={styles.inputContainer}>
        <TextInput
          style={styles.textInput}
          value={inputText}
          onChangeText={setInputText}
          placeholder="Ask about emergency procedures, safety tips..."
          placeholderTextColor="#999"
          multiline
          maxLength={500}
          editable={!isLoading && modelStatus === 'ready'}
        />
        <TouchableOpacity
          style={[
            styles.sendButton,
            (!inputText.trim() || isLoading || isTyping || modelStatus !== 'ready') && styles.sendButtonDisabled
          ]}
          onPress={handleSend}
          disabled={!inputText.trim() || isLoading || isTyping || modelStatus !== 'ready'}
        >
          <Text style={styles.sendButtonText}>Send</Text>
        </TouchableOpacity>
      </View>

      {/* Loading Overlay */}
      {isLoading && (
        <View style={styles.loadingOverlay}>
          <ActivityIndicator size="large" color="#007AFF" />
          <Text style={styles.loadingText}>Loading offline model...</Text>
        </View>
      )}
    </KeyboardAvoidingView>
  );
};

/**
 * Comprehensive styles for the LocalChatbot component
 * Optimized for mobile devices with accessibility in mind
 */
const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f5f5f5',
  },
  
  // Header styles
  header: {
    backgroundColor: '#007AFF',
    paddingTop: Platform.OS === 'ios' ? 50 : 25,
    paddingBottom: 15,
    paddingHorizontal: 20,
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  headerTitle: {
    color: 'white',
    fontSize: 18,
    fontWeight: 'bold',
    flex: 1,
  },
  statusIndicator: {
    paddingHorizontal: 12,
    paddingVertical: 6,
    borderRadius: 15,
    marginLeft: 10,
  },
  statusText: {
    color: 'white',
    fontSize: 12,
    fontWeight: '600',
  },

  // Messages styles
  messagesList: {
    flex: 1,
    backgroundColor: '#f5f5f5',
  },
  messagesContent: {
    paddingVertical: 10,
  },
  messageContainer: {
    marginVertical: 4,
    marginHorizontal: 15,
  },
  userMessageContainer: {
    alignItems: 'flex-end',
  },
  assistantMessageContainer: {
    alignItems: 'flex-start',
  },
  systemMessageContainer: {
    alignItems: 'center',
  },
  messageBubble: {
    maxWidth: screenWidth * 0.8,
    padding: 12,
    borderRadius: 18,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 2,
  },
  userBubble: {
    backgroundColor: '#007AFF',
    borderBottomRightRadius: 4,
  },
  assistantBubble: {
    backgroundColor: 'white',
    borderBottomLeftRadius: 4,
  },
  systemBubble: {
    backgroundColor: '#FFF3CD',
    borderRadius: 8,
    maxWidth: screenWidth * 0.9,
  },
  messageText: {
    fontSize: 16,
    lineHeight: 22,
  },
  userText: {
    color: 'white',
  },
  assistantText: {
    color: '#333',
  },
  systemText: {
    color: '#856404',
    fontSize: 14,
    textAlign: 'center',
  },
  timestamp: {
    fontSize: 12,
    marginTop: 6,
    opacity: 0.7,
  },
  userTimestamp: {
    color: 'white',
    textAlign: 'right',
  },
  assistantTimestamp: {
    color: '#666',
  },

  // Typing indicator styles
  typingContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 20,
    paddingVertical: 10,
    backgroundColor: '#f5f5f5',
  },
  typingText: {
    marginLeft: 10,
    color: '#666',
    fontStyle: 'italic',
  },

  // Input area styles
  inputContainer: {
    flexDirection: 'row',
    paddingHorizontal: 15,
    paddingVertical: 10,
    backgroundColor: 'white',
    borderTopWidth: 1,
    borderTopColor: '#e0e0e0',
    alignItems: 'flex-end',
  },
  textInput: {
    flex: 1,
    borderWidth: 1,
    borderColor: '#e0e0e0',
    borderRadius: 20,
    paddingHorizontal: 15,
    paddingVertical: 10,
    maxHeight: 100,
    fontSize: 16,
    backgroundColor: '#f9f9f9',
  },
  sendButton: {
    backgroundColor: '#007AFF',
    paddingHorizontal: 20,
    paddingVertical: 10,
    borderRadius: 20,
    marginLeft: 10,
    justifyContent: 'center',
    alignItems: 'center',
  },
  sendButtonDisabled: {
    backgroundColor: '#cccccc',
  },
  sendButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: '600',
  },

  // Loading overlay styles
  loadingOverlay: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    backgroundColor: 'rgba(0, 0, 0, 0.7)',
    justifyContent: 'center',
    alignItems: 'center',
  },
  loadingText: {
    color: 'white',
    fontSize: 16,
    marginTop: 10,
  },
});

export default LocalChatbot;