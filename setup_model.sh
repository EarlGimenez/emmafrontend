#!/bin/bash

# Setup script for downloading the offline LLM model for disaster relief chatbot
# This script downloads a lightweight Gemma model optimized for mobile deployment
# The model will be stored locally to enable offline functionality

set -e  # Exit on any error

# Model configuration
MODEL_URL="https://huggingface.co/TheBloke/gemma-3-270m-GGUF/resolve/main/gemma-3-270m.q4_k_m.gguf"
TARGET_DIR="assets/models"
MODEL_FILE="gemma-3-270m.q4_k_m.gguf"
FULL_PATH="$TARGET_DIR/$MODEL_FILE"

echo "ğŸš€ Starting offline chatbot model setup..."
echo "ğŸ“ Target directory: $TARGET_DIR"
echo "ğŸ“¦ Model file: $MODEL_FILE"

# Create the models directory if it doesn't exist
if [ ! -d "$TARGET_DIR" ]; then
    echo "ğŸ“ Creating models directory..."
    mkdir -p "$TARGET_DIR"
    echo "âœ… Directory created successfully"
else
    echo "ğŸ“ Models directory already exists"
fi

# Check if model already exists
if [ -f "$FULL_PATH" ]; then
    echo "âš ï¸  Model file already exists. Do you want to re-download? (y/N)"
    read -r response
    if [[ ! "$response" =~ ^[Yy]$ ]]; then
        echo "âœ… Using existing model file"
        exit 0
    fi
    echo "ğŸ—‘ï¸  Removing existing model file..."
    rm "$FULL_PATH"
fi

# Download the model
echo "â¬¬ Downloading model from Hugging Face..."
echo "ğŸ“Š Model size: ~150MB (optimized for mobile)"
echo "â³ This may take a few minutes depending on your connection..."

if curl -L --fail --show-error --progress-bar -o "$FULL_PATH" "$MODEL_URL"; then
    echo "âœ… Model downloaded successfully!"
    echo "ğŸ“ Model location: $FULL_PATH"
    
    # Verify the download
    if [ -f "$FULL_PATH" ]; then
        # Get file size in a portable way
        if [[ "$OSTYPE" == "darwin"* ]]; then
            file_size=$(stat -f%z "$FULL_PATH")
        else
            file_size=$(stat -c%s "$FULL_PATH")
        fi
        echo "ğŸ“Š Downloaded file size: $file_size bytes"
        echo "ğŸ‰ Setup complete! Your offline chatbot is ready to use."
        echo ""
        echo "Next steps:"
        echo "1. Import the LocalChatbot component in your app"
        echo "2. The model will be automatically loaded when the component mounts"
        echo "3. No internet connection required for inference!"
    else
        echo "âŒ Error: Model file not found after download"
        exit 1
    fi
else
    echo "âŒ Error: Failed to download model"
    echo "ğŸ”§ Troubleshooting:"
    echo "   - Check your internet connection"
    echo "   - Verify the Hugging Face URL is accessible"
    echo "   - Ensure you have sufficient disk space (~200MB)"
    exit 1
fi

echo ""
echo "ğŸŒ Offline disaster relief chatbot setup complete!"
echo "ğŸ’¡ This model works entirely offline - perfect for emergency situations."
